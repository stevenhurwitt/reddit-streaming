{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b74b8dbb",
   "metadata": {},
   "source": [
    "# Read Partitioned Data in Parquet Format and Write Updates #\n",
    "This notebook demostrates reading partitioned data, partition filter operations and writing updated partitions back to the storage layer.  \n",
    "  \n",
    "This notebook is dependant on the output data created by the notebook `creditcard_hash_anonymize.ipnyb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0845997b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/02/23 08:20:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"hash_anon_partitions\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        config(\"spark.eventLog.enabled\", \"true\").\\\n",
    "        config(\"spark.eventLog.dir\", \"file:///opt/workspace/events\").\\\n",
    "        getOrCreate()      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef94bc8",
   "metadata": {},
   "source": [
    "# Read Parquet Data #\n",
    "\n",
    "### Configuration Setting to allow partition writes back ###\n",
    "Missing this configuration option results in\n",
    "\n",
    "```\n",
    "java.io.FileNotFoundException ...   \n",
    "It is possible the underlying files have been updated. You can explicitly invalidate the cache in Spark by running 'REFRESH TABLE tableName' command in SQL or by recreating the Dataset/DataFrame involved.\n",
    "```\n",
    "\n",
    "AND *all the data in the updated partition is deleted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7cb3037",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.sources.partitionOverwriteMode', 'dynamic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5769cb",
   "metadata": {},
   "source": [
    "### Demonstrate Partition Filtering ###\n",
    "Without Parquet filter by partition, we scan 132 partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed883142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan parquet [card_type#0,bank#1,card_number#2,card_holder#3,expiry_date#4,billing_date#5,credit_limit#6,issue_year#7,issue_month#8] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/opt/workspace/dataout/credit-cards], PartitionCount: 132, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<card_type:string,bank:string,card_number:string,card_holder:string,expiry_date:string,bill...\n"
     ]
    }
   ],
   "source": [
    "df_read = spark.read.parquet(\"/opt/workspace/dataout/credit-cards/\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e92d390",
   "metadata": {},
   "source": [
    "With a filter by year, we only scan PartitionCount: 12 (12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfc0c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan parquet [card_type#18,bank#19,card_number#20,card_holder#21,expiry_date#22,billing_date#23,credit_limit#24,issue_month#25] Batched: true, Format: Parquet, Location: InMemoryFileIndex[file:/opt/workspace/dataout/credit-cards/issue_year=2013], PartitionCount: 12, PartitionFilters: [], PushedFilters: [], ReadSchema: struct<card_type:string,bank:string,card_number:string,card_holder:string,expiry_date:string,bill...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_read = spark.read.parquet(\"/opt/workspace/dataout/credit-cards/issue_year=2013\").explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b31f5c",
   "metadata": {},
   "source": [
    "### Read in Partition Data for year 2013 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d904b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the basePath option to stop the partition column from being dropped\n",
    "df_read = spark.read.option(\"basePath\", \"/opt/workspace/dataout/credit-cards/\").parquet(\"/opt/workspace/dataout/credit-cards/issue_year=2013\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5571cc",
   "metadata": {},
   "source": [
    "# Save updates to a Partition #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce22c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|          card_type|            bank|         card_number|         card_holder|expiry_date|billing_date|credit_limit|issue_year|issue_month|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|   American Express|American Express|fa97545a484641d8a...|1b5f1b515cab9b586...|    08/2027|           1|      104100|      2013|          8|\n",
      "|               Visa|  First National|70af4edc8e5c207e3...|a2cde7687a0e544a8...|    08/2015|          21|       55300|      2013|          8|\n",
      "|        Master Card|           Chase|73ab033eaade21c1c...|e8c999919fa7720d5...|    08/2028|           9|      171900|      2013|          8|\n",
      "|           Discover|        Discover|87deb4b3c75c3b79f...|ac7ca170a090c60a1...|    08/2030|          11|      137200|      2013|          8|\n",
      "|Japan Credit Bureau|             JCB|de3a1dce962d0f74c...|6be7c5c47ba3c8de5...|    08/2015|          25|       76600|      2013|          8|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_read.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106a891c",
   "metadata": {},
   "source": [
    "NOTE - we have lost the leading 0 for the month.  This is because the type of the partition column has been re-inferred (int not String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a85f71b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- bank: string (nullable = true)\n",
      " |-- card_number: string (nullable = true)\n",
      " |-- card_holder: string (nullable = true)\n",
      " |-- expiry_date: string (nullable = true)\n",
      " |-- billing_date: integer (nullable = true)\n",
      " |-- credit_limit: integer (nullable = true)\n",
      " |-- issue_year: integer (nullable = true)\n",
      " |-- issue_month: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc35b5f",
   "metadata": {},
   "source": [
    "try again with spark.sql.sources.partitionColumnTypeInference.enabled set to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1db3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.sources.partitionColumnTypeInference.enabled', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e7ef250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = spark.read.option(\"basePath\", \"/opt/workspace/dataout/credit-cards/\").parquet(\"/opt/workspace/dataout/credit-cards/issue_year=2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57ede5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- card_type: string (nullable = true)\n",
      " |-- bank: string (nullable = true)\n",
      " |-- card_number: string (nullable = true)\n",
      " |-- card_holder: string (nullable = true)\n",
      " |-- expiry_date: string (nullable = true)\n",
      " |-- billing_date: integer (nullable = true)\n",
      " |-- credit_limit: integer (nullable = true)\n",
      " |-- issue_year: string (nullable = true)\n",
      " |-- issue_month: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_read.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8206cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|          card_type|            bank|         card_number|         card_holder|expiry_date|billing_date|credit_limit|issue_year|issue_month|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|   American Express|American Express|fa97545a484641d8a...|1b5f1b515cab9b586...|    08/2027|           1|      104100|      2013|         08|\n",
      "|               Visa|  First National|70af4edc8e5c207e3...|a2cde7687a0e544a8...|    08/2015|          21|       55300|      2013|         08|\n",
      "|        Master Card|           Chase|73ab033eaade21c1c...|e8c999919fa7720d5...|    08/2028|           9|      171900|      2013|         08|\n",
      "|           Discover|        Discover|87deb4b3c75c3b79f...|ac7ca170a090c60a1...|    08/2030|          11|      137200|      2013|         08|\n",
      "|Japan Credit Bureau|             JCB|de3a1dce962d0f74c...|6be7c5c47ba3c8de5...|    08/2015|          25|       76600|      2013|         08|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_read.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d7baf",
   "metadata": {},
   "source": [
    "We now have the leading zero on the issue_month string retained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b3a54",
   "metadata": {},
   "source": [
    "### Change the partition data and write it back ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e954ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase the credit_limit by factor 10\n",
    "df_update = df_read.withColumn(\"credit_limit\", df_read.credit_limit*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6607000c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|          card_type|            bank|         card_number|         card_holder|expiry_date|billing_date|credit_limit|issue_year|issue_month|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|   American Express|American Express|fa97545a484641d8a...|1b5f1b515cab9b586...|    08/2027|           1|     1041000|      2013|         08|\n",
      "|               Visa|  First National|70af4edc8e5c207e3...|a2cde7687a0e544a8...|    08/2015|          21|      553000|      2013|         08|\n",
      "|        Master Card|           Chase|73ab033eaade21c1c...|e8c999919fa7720d5...|    08/2028|           9|     1719000|      2013|         08|\n",
      "|           Discover|        Discover|87deb4b3c75c3b79f...|ac7ca170a090c60a1...|    08/2030|          11|     1372000|      2013|         08|\n",
      "|Japan Credit Bureau|             JCB|de3a1dce962d0f74c...|6be7c5c47ba3c8de5...|    08/2015|          25|      766000|      2013|         08|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_update.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83550ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_update.write.format(\"parquet\")\\\n",
    "                .mode(\"overwrite\")\\\n",
    "                .partitionBy('issue_year', 'issue_month')\\\n",
    "                .save(\"/opt/workspace/dataout/credit-cards/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212d4358",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2920a5e5",
   "metadata": {},
   "source": [
    "### Check the Updates to the Partition ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e0eac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"hash_anon_readupdate\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        config(\"spark.eventLog.enabled\", \"true\").\\\n",
    "        config(\"spark.eventLog.dir\", \"file:///opt/workspace/events\").\\\n",
    "        getOrCreate()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f6cd9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|          card_type|            bank|         card_number|         card_holder|expiry_date|billing_date|credit_limit|issue_year|issue_month|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "|   American Express|American Express|fa97545a484641d8a...|1b5f1b515cab9b586...|    08/2027|           1|     1041000|      2013|          8|\n",
      "|               Visa|  First National|70af4edc8e5c207e3...|a2cde7687a0e544a8...|    08/2015|          21|      553000|      2013|          8|\n",
      "|        Master Card|           Chase|73ab033eaade21c1c...|e8c999919fa7720d5...|    08/2028|           9|     1719000|      2013|          8|\n",
      "|           Discover|        Discover|87deb4b3c75c3b79f...|ac7ca170a090c60a1...|    08/2030|          11|     1372000|      2013|          8|\n",
      "|Japan Credit Bureau|             JCB|de3a1dce962d0f74c...|6be7c5c47ba3c8de5...|    08/2015|          25|      766000|      2013|          8|\n",
      "+-------------------+----------------+--------------------+--------------------+-----------+------------+------------+----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_read = spark.read.option(\"basePath\", \"/opt/workspace/dataout/credit-cards/\").parquet(\"/opt/workspace/dataout/credit-cards/issue_year=2013\")\n",
    "df_read.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e743638c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbaa65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
