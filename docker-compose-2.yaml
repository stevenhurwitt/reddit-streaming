version: "3"
volumes:
  shared-workspace:
    # name: "hadoop-distributed-file-system"
    # driver: local
  postgres-db-volume:
services:
  jupyterlab:
    image: stevenhurwitt/jupyterlab
    container_name: jupyterlab
    environment:
      - JUPYTER_TOKEN=easy
    networks:
      - reddit_streaming
    ports:
      - 8899:8888
    volumes:
      - shared-workspace:/opt/workspace
      - ./redditStreaming:/opt/workspace/redditStreaming

  spark-master:
    image: stevenhurwitt/spark-master
    container_name: spark-master
    hostname: spark-master
    networks:
      - reddit_streaming
    ports:
      - 8008:8080
      - 7077:7077
      - 4004:4040
    volumes:
      - shared-workspace:/opt/workspace

  spark-worker-1:
    image: stevenhurwitt/spark-worker
    container_name: spark-worker-1
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=16g
    ports:
      - 4041:4040
      - 18081:18080
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - reddit_streaming

  spark-worker-2:
    image: stevenhurwitt/spark-worker
    container_name: spark-worker-2
    environment:
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=16g
    ports:
      - 4042:4040
      - 18082:18080
    volumes:
      - shared-workspace:/opt/workspace
    depends_on:
      - spark-master
    networks:
      - reddit_streaming

  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: Secret!12345
      # POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always
    hostname: postgres
    networks:
      - reddit_streaming
    ports: 
      - "5432:5432"

  zookeeper:
    # image: wurstmeister/zookeeper
    image: ghcr.io/arm64-compat/confluentinc/cp-zookeeper:7.1.1
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - reddit_streaming
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    restart: always
    volumes:
      - ./cluster_config/zookeeper/data:/opt/zookeeper-3.4.13/data

  # kafka:
  #   # image: wurstmeister/kafka
  #   image: ghcr.io/arm64-compat/confluentinc/cp-kafka:7.1.1
  #   container_name: kafka
  #   hostname: kafka
  #   networks:
  #     - reddit_streaming
  #   ports:
  #     - "9092:9092"
  #   environment:
  #     # KAFKA_ADVERTISED_HOST_NAME: 172.16.100.35  #ip of local machine
  #     KAFKA_ADVERTISED_HOST_NAME: 10.0.0.26
  #     # KAFKA_ADVERTISED_PORT: 9092
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://host.docker.internal:9092
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
  #     KAFKA_LOG_DIRS: /kafka/kafka-logs
  #     KAFKA_BROKER_ID: 999 # comment out if using multiple brokers
  #     # KAFKA_CREATE_TOPICS: "test-topic:5:2"
  #     KAFKA_DEFAULT_REPLICATION_FACTOR: 1
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   restart: always
  #   depends_on:
  #     - zookeeper
  #   # entrypoint: /tmp/entrypoint.sh
  #   volumes: 
  #     - ./cluster_config/kafka/logs:/kafka/kafka-logs
  #     - ./cluster_config/kafka/config:/opt/kafka/config
  #     # - ./entrypoint.sh:/tmp/entrypoint.sh
  #     - /var/run/docker.sock:/var/run/docker.sock

  redpanda:
    image: vectorized/redpanda:v22.1.3
    command:
      - redpanda start
      - --smp 1
      - --overprovisioned
      - --node-id 0
      - --kafka-addr PLAINTEXT://0.0.0.0:29092,OUTSIDE://0.0.0.0:9092
      - --advertise-kafka-addr PLAINTEXT://redpanda:29092,OUTSIDE://localhost:9092
      - --pandaproxy-addr 0.0.0.0:8082
      - --advertise-pandaproxy-addr localhost:8082
    ports:
      - 8081:8081
      - 8082:8082
      - 9092:9092
      - 29092:29092
    hostname: redpanda
    container_name: redpanda

  kowl:
    image: docker.redpanda.com/vectorized/console:master-0a8fce8
    restart: on-failure
    entrypoint: /bin/sh
    command: -c "echo \"$$CONSOLE_CONFIG_FILE\" > /tmp/config.yml; /app/kowl"
    environment:
      CONFIG_FILEPATH: /tmp/config.yml
      CONSOLE_CONFIG_FILE: |
        kafka:
          brokers: ["redpanda:29092"]
          schemaRegistry:
            enabled: true
            urls: ["http://redpanda:8081"]
        connect:
          enabled: true
          clusters:
            - name: datagen
              url: http://connect:8083
    ports:
      - "8080:8080"
    depends_on:
      - redpanda

  connect:
    image: cnfldemos/cp-server-connect-datagen:0.5.0-6.2.0
    hostname: connect
    container_name: connect
    depends_on:
      - redpanda
    ports:
      - "8083:8083"
    environment:
      CONNECT_BOOTSTRAP_SERVERS: 'redpanda:29092'
      CONNECT_REST_ADVERTISED_HOST_NAME: connect
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://redpanda:8081
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components"
      CONNECT_LOG4J_LOGGERS: org.apache.zookeeper=ERROR,org.I0Itec.zkclient=ERROR,org.reflections=ERROR

  owl-shop:
    #image: quay.io/cloudhut/owl-shop:v1.2.0
    image: quay.io/cloudhut/owl-shop:latest
    environment:
      - SHOP_KAFKA_BROKERS=redpanda:29092
      - SHOP_KAFKA_TOPICREPLICATIONFACTOR=1
      - SHOP_TRAFFIC_INTERVAL_RATE=1
      - SHOP_TRAFFIC_INTERVAL_DURATION=0.1s
    depends_on:
      - redpanda

networks:
  reddit_streaming:
    driver: "bridge"
