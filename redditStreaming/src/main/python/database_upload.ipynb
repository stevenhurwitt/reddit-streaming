{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# database upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting delta\n",
      "  Downloading delta-0.4.2.tar.gz (4.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: delta\n",
      "  Building wheel for delta (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for delta: filename=delta-0.4.2-py3-none-any.whl size=2915 sha256=05c5bedc488b62566c325ee63e1fbf74b684adb2c310bb9be404f181ecebd903\n",
      "  Stored in directory: /root/.cache/pip/wheels/55/5f/9c/72abeef3691350b738e0d20b8f8c8133174ae76b9e022d4a41\n",
      "Successfully built delta\n",
      "Installing collected packages: delta\n",
      "Successfully installed delta-0.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# ! pip3 install psycopg2 delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported modules.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import psycopg2\n",
    "import datetime as dt\n",
    "from delta import *\n",
    "import boto3\n",
    "import pprint\n",
    "import yaml\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent = 1)\n",
    "print(\"imported modules.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read creds.json.\n",
      "read creds successfully.\n"
     ]
    }
   ],
   "source": [
    "creds_path = os.path.join(\"/opt\", \"workspace\", \"redditStreaming\", \"creds.json\")\n",
    "\n",
    "try:\n",
    "    with open(creds_path, \"r\") as f:\n",
    "        creds = json.load(f)\n",
    "        print(\"read creds.json.\")\n",
    "        f.close()\n",
    "\n",
    "except:\n",
    "    creds_path = \"/home/steven/Documents/reddit-streaming/redditStreaming/creds.json\"\n",
    "    with open(creds_path, \"r\") as f:\n",
    "        creds = json.load(f)\n",
    "        print(\"read creds.json.\")\n",
    "        f.close()\n",
    "\n",
    "print(\"read creds successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "An error occurred (InvalidClientTokenId) when calling the GetSessionToken operation: The security token included in the request is invalid.\n"
     ]
    }
   ],
   "source": [
    "! aws sts get-session-token \\\n",
    "    --serial-number arn:aws:iam::202946765941:mfa/steven \\\n",
    "    --token-code 780588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (UnrecognizedClientException) when calling the GetSecretValue operation: The security token included in the request is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python/database_upload.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.12.117/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python/database_upload.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m secretmanager_client \u001b[39m=\u001b[39m boto3\u001b[39m.\u001b[39mclient(\u001b[39m\"\u001b[39m\u001b[39msecretsmanager\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.12.117/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python/database_upload.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m                                     region_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mus-east-2\u001b[39m\u001b[39m\"\u001b[39m, \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.12.117/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python/database_upload.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                                     aws_access_key_id \u001b[39m=\u001b[39m creds[\u001b[39m\"\u001b[39m\u001b[39maws_client\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.12.117/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python/database_upload.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                                     aws_secret_access_key \u001b[39m=\u001b[39m creds[\u001b[39m\"\u001b[39m\u001b[39maws_secret\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.12.117/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python/database_upload.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m response \u001b[39m=\u001b[39m secretmanager_client\u001b[39m.\u001b[39mget_secret_value(SecretId\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdev/reddit/postgres\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B192.168.12.117/home/steven/Documents/reddit-streaming/redditStreaming/src/main/python/database_upload.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/reddit/lib/python3.10/site-packages/botocore/client.py:508\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    505\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpy_operation_name\u001b[39m}\u001b[39;00m\u001b[39m() only accepts keyword arguments.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m \u001b[39m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_api_call(operation_name, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/reddit/lib/python3.10/site-packages/botocore/client.py:915\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    913\u001b[0m     error_code \u001b[39m=\u001b[39m parsed_response\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mError\u001b[39m\u001b[39m\"\u001b[39m, {})\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    914\u001b[0m     error_class \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m--> 915\u001b[0m     \u001b[39mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m    916\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[39mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (UnrecognizedClientException) when calling the GetSecretValue operation: The security token included in the request is invalid."
     ]
    }
   ],
   "source": [
    "secretmanager_client = boto3.client(\"secretsmanager\", \n",
    "                                    region_name = \"us-east-2\", \n",
    "                                    aws_access_key_id = creds[\"aws_client\"], \n",
    "                                    aws_secret_access_key = creds[\"aws_secret\"])\n",
    "\n",
    "response = secretmanager_client.get_secret_value(SecretId=\"dev/reddit/postgres\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/steven/.ivy2/cache\n",
      "The jars for the packages stored in: /home/steven/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-common added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.apache.hadoop#hadoop-client added as a dependency\n",
      "io.delta#delta-core_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-77c9b516-e964-4856-9871-262205ccbc16;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.1 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.1 in central\n",
      "\tfound org.apache.kafka#kafka-clients;2.8.1 in local-m2-cache\n",
      "\tfound org.lz4#lz4-java;1.8.0 in local-m2-cache\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.8.4 in local-m2-cache\n",
      "\tfound org.slf4j#slf4j-api;1.7.32 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.2 in local-m2-cache\n",
      "\tfound org.spark-project.spark#unused;1.0.0 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.2 in local-m2-cache\n",
      "\tfound commons-logging#commons-logging;1.1.3 in local-m2-cache\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in local-m2-cache\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-common;3.3.1 in local-m2-cache\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-protobuf_3_7;1.1.1 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-annotations;3.3.1 in local-m2-cache\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in local-m2-cache\n",
      "\tfound com.google.guava#guava;27.0-jre in local-m2-cache\n",
      "\tfound com.google.guava#failureaccess;1.0 in local-m2-cache\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in local-m2-cache\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in local-m2-cache\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in local-m2-cache\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in local-m2-cache\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in local-m2-cache\n",
      "\tfound commons-cli#commons-cli;1.2 in local-m2-cache\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in local-m2-cache\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in local-m2-cache\n",
      "\tfound commons-codec#commons-codec;1.11 in local-m2-cache\n",
      "\tfound commons-io#commons-io;2.8.0 in local-m2-cache\n",
      "\tfound commons-net#commons-net;3.6 in local-m2-cache\n",
      "\tfound commons-collections#commons-collections;3.2.2 in local-m2-cache\n",
      "\tfound javax.servlet#javax.servlet-api;3.1.0 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-server;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-http;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-io;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-servlet;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-security;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-webapp;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound org.eclipse.jetty#jetty-xml;9.4.40.v20210413 in local-m2-cache\n",
      "\tfound com.sun.jersey#jersey-core;1.19 in local-m2-cache\n",
      "\tfound javax.ws.rs#jsr311-api;1.1.1 in local-m2-cache\n",
      "\tfound com.sun.jersey#jersey-servlet;1.19 in local-m2-cache\n",
      "\tfound com.sun.jersey#jersey-server;1.19 in local-m2-cache\n",
      "\tfound com.sun.jersey#jersey-json;1.19 in local-m2-cache\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in local-m2-cache\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in local-m2-cache\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.11 in local-m2-cache\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in local-m2-cache\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in local-m2-cache\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in local-m2-cache\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in local-m2-cache\n",
      "\tfound log4j#log4j;1.2.17 in local-m2-cache\n",
      "\tfound commons-beanutils#commons-beanutils;1.9.4 in local-m2-cache\n",
      "\tfound org.apache.commons#commons-configuration2;2.1.1 in local-m2-cache\n",
      "\tfound org.apache.commons#commons-lang3;3.7 in local-m2-cache\n",
      "\tfound org.apache.commons#commons-text;1.4 in local-m2-cache\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.30 in local-m2-cache\n",
      "\tfound org.apache.avro#avro;1.7.7 in local-m2-cache\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in local-m2-cache\n",
      "\tfound org.apache.commons#commons-compress;1.19 in local-m2-cache\n",
      "\tfound com.google.re2j#re2j;1.1 in local-m2-cache\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in local-m2-cache\n",
      "\tfound com.google.code.gson#gson;2.2.4 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-auth;3.3.1 in local-m2-cache\n",
      "\tfound com.nimbusds#nimbus-jose-jwt;9.8.1 in local-m2-cache\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in local-m2-cache\n",
      "\tfound net.minidev#json-smart;2.4.2 in local-m2-cache\n",
      "\tfound net.minidev#accessors-smart;2.4.2 in local-m2-cache\n",
      "\tfound org.ow2.asm#asm;5.0.4 in local-m2-cache\n",
      "\tfound org.apache.zookeeper#zookeeper;3.5.6 in local-m2-cache\n",
      "\tfound org.apache.zookeeper#zookeeper-jute;3.5.6 in local-m2-cache\n",
      "\tfound org.apache.yetus#audience-annotations;0.5.0 in local-m2-cache\n",
      "\tfound org.apache.curator#curator-framework;4.2.0 in local-m2-cache\n",
      "\tfound org.apache.curator#curator-client;4.2.0 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-simplekdc;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-client;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerby-config;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-core;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerby-pkix;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerby-asn1;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerby-util;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-common;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-crypto;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-util;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#token-provider;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-admin;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-server;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerb-identity;1.0.1 in local-m2-cache\n",
      "\tfound org.apache.kerby#kerby-xdr;1.0.1 in local-m2-cache\n",
      "\tfound com.jcraft#jsch;0.1.55 in local-m2-cache\n",
      "\tfound org.apache.curator#curator-recipes;4.2.0 in local-m2-cache\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in local-m2-cache\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.10.5.1 in local-m2-cache\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.10.5 in local-m2-cache\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in local-m2-cache\n",
      "\tfound org.codehaus.woodstox#stax2-api;4.2.1 in local-m2-cache\n",
      "\tfound com.fasterxml.woodstox#woodstox-core;5.3.0 in local-m2-cache\n",
      "\tfound dnsjava#dnsjava;2.1.7 in local-m2-cache\n",
      "\tfound jakarta.activation#jakarta.activation-api;1.2.1 in local-m2-cache\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.apache.hadoop#hadoop-client;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-hdfs-client;3.3.1 in central\n",
      "\tfound com.squareup.okhttp#okhttp;2.7.5 in local-m2-cache\n",
      "\tfound com.squareup.okio#okio;1.6.0 in local-m2-cache\n",
      "\tfound org.apache.hadoop#hadoop-yarn-api;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-client;3.3.1 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-client;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-client;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-common;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-api;9.4.40.v20210413 in central\n",
      "\tfound org.jline#jline;3.9.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-core;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-common;3.3.1 in central\n",
      "\tfound com.sun.jersey#jersey-client;1.19 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 in central\n",
      "\tfound jakarta.xml.bind#jakarta.xml.bind-api;2.3.2 in central\n",
      "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 in central\n",
      "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-jobclient;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-common;3.3.1 in central\n",
      "\tfound io.delta#delta-core_2.12;1.2.1 in central\n",
      "\tfound io.delta#delta-storage;1.2.1 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.8 in local-m2-cache\n",
      "\tfound org.postgresql#postgresql;42.5.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in local-m2-cache\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.3.1/spark-sql-kafka-0-10_2.12-3.3.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.3.1!spark-sql-kafka-0-10_2.12.jar (296ms)\n",
      "downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.5.0/postgresql-42.5.0.jar ...\n",
      "\t[SUCCESSFUL ] org.postgresql#postgresql;42.5.0!postgresql.jar (956ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.3.1/spark-token-provider-kafka-0-10_2.12-3.3.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.1!spark-token-provider-kafka-0-10_2.12.jar (63ms)\n",
      "downloading file:/home/steven/.m2/repository/org/apache/kafka/kafka-clients/2.8.1/kafka-clients-2.8.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.8.1!kafka-clients.jar (17ms)\n",
      "downloading file:/home/steven/.m2/repository/org/apache/commons/commons-pool2/2.11.1/commons-pool2-2.11.1.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.commons#commons-pool2;2.11.1!commons-pool2.jar (3ms)\n",
      "downloading file:/home/steven/.m2/repository/org/apache/hadoop/hadoop-client-runtime/3.3.2/hadoop-client-runtime-3.3.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-runtime;3.3.2!hadoop-client-runtime.jar (35ms)\n",
      "downloading file:/home/steven/.m2/repository/org/lz4/lz4-java/1.8.0/lz4-java-1.8.0.jar ...\n",
      "\t[SUCCESSFUL ] org.lz4#lz4-java;1.8.0!lz4-java.jar (1ms)\n",
      "downloading file:/home/steven/.m2/repository/org/slf4j/slf4j-api/1.7.32/slf4j-api-1.7.32.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.32!slf4j-api.jar (0ms)\n",
      "downloading file:/home/steven/.m2/repository/org/apache/hadoop/hadoop-client-api/3.3.2/hadoop-client-api-3.3.2.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.hadoop#hadoop-client-api;3.3.2!hadoop-client-api.jar (14ms)\n",
      "downloading file:/home/steven/.m2/repository/commons-net/commons-net/3.6/commons-net-3.6.jar ...\n",
      "\t[SUCCESSFUL ] commons-net#commons-net;3.6!commons-net.jar (1ms)\n",
      "downloading file:/home/steven/.m2/repository/org/checkerframework/checker-qual/3.5.0/checker-qual-3.5.0.jar ...\n",
      "\t[SUCCESSFUL ] org.checkerframework#checker-qual;3.5.0!checker-qual.jar (1ms)\n",
      ":: resolution report :: resolve 7750ms :: artifacts dl 1432ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.10.5 from local-m2-cache in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from local-m2-cache in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.10.5.1 from local-m2-cache in [default]\n",
      "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.woodstox#woodstox-core;5.3.0 from local-m2-cache in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from local-m2-cache in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from local-m2-cache in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from local-m2-cache in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from local-m2-cache in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from local-m2-cache in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from local-m2-cache in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from local-m2-cache in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from local-m2-cache in [default]\n",
      "\tcom.google.re2j#re2j;1.1 from local-m2-cache in [default]\n",
      "\tcom.jcraft#jsch;0.1.55 from local-m2-cache in [default]\n",
      "\tcom.nimbusds#nimbus-jose-jwt;9.8.1 from local-m2-cache in [default]\n",
      "\tcom.squareup.okhttp#okhttp;2.7.5 from local-m2-cache in [default]\n",
      "\tcom.squareup.okio#okio;1.6.0 from local-m2-cache in [default]\n",
      "\tcom.sun.jersey#jersey-client;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.19 from local-m2-cache in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.19 from local-m2-cache in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.19 from local-m2-cache in [default]\n",
      "\tcom.sun.jersey#jersey-servlet;1.19 from local-m2-cache in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from local-m2-cache in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from local-m2-cache in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.9.4 from local-m2-cache in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from local-m2-cache in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from local-m2-cache in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from local-m2-cache in [default]\n",
      "\tcommons-io#commons-io;2.8.0 from local-m2-cache in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from local-m2-cache in [default]\n",
      "\tcommons-net#commons-net;3.6 from local-m2-cache in [default]\n",
      "\tdnsjava#dnsjava;2.1.7 from local-m2-cache in [default]\n",
      "\tio.delta#delta-core_2.12;1.2.1 from central in [default]\n",
      "\tio.delta#delta-storage;1.2.1 from central in [default]\n",
      "\tjakarta.activation#jakarta.activation-api;1.2.1 from local-m2-cache in [default]\n",
      "\tjakarta.xml.bind#jakarta.xml.bind-api;2.3.2 from central in [default]\n",
      "\tjavax.servlet#javax.servlet-api;3.1.0 from local-m2-cache in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from local-m2-cache in [default]\n",
      "\tjavax.ws.rs#jsr311-api;1.1.1 from local-m2-cache in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.11 from local-m2-cache in [default]\n",
      "\tlog4j#log4j;1.2.17 from local-m2-cache in [default]\n",
      "\tnet.minidev#accessors-smart;2.4.2 from local-m2-cache in [default]\n",
      "\tnet.minidev#json-smart;2.4.2 from local-m2-cache in [default]\n",
      "\torg.antlr#antlr4-runtime;4.8 from local-m2-cache in [default]\n",
      "\torg.apache.avro#avro;1.7.7 from local-m2-cache in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from local-m2-cache in [default]\n",
      "\torg.apache.commons#commons-configuration2;2.1.1 from local-m2-cache in [default]\n",
      "\torg.apache.commons#commons-lang3;3.7 from local-m2-cache in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from local-m2-cache in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from local-m2-cache in [default]\n",
      "\torg.apache.commons#commons-text;1.4 from local-m2-cache in [default]\n",
      "\torg.apache.curator#curator-client;4.2.0 from local-m2-cache in [default]\n",
      "\torg.apache.curator#curator-framework;4.2.0 from local-m2-cache in [default]\n",
      "\torg.apache.curator#curator-recipes;4.2.0 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;3.3.1 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;3.3.1 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.2 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.2 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-common;3.3.1 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop#hadoop-hdfs-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-core;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-jobclient;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from local-m2-cache in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-protobuf_3_7;1.1.1 from local-m2-cache in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from local-m2-cache in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from local-m2-cache in [default]\n",
      "\torg.apache.kafka#kafka-clients;2.8.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-admin;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-client;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-common;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-core;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-crypto;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-identity;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-server;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-simplekdc;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerb-util;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerby-asn1;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerby-config;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerby-pkix;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerby-util;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#kerby-xdr;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.kerby#token-provider;1.0.1 from local-m2-cache in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.3.1 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.3.1 from central in [default]\n",
      "\torg.apache.yetus#audience-annotations;0.5.0 from local-m2-cache in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.5.6 from local-m2-cache in [default]\n",
      "\torg.apache.zookeeper#zookeeper-jute;3.5.6 from local-m2-cache in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 from local-m2-cache in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from local-m2-cache in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from local-m2-cache in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from local-m2-cache in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from local-m2-cache in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from local-m2-cache in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from local-m2-cache in [default]\n",
      "\torg.codehaus.woodstox#stax2-api;4.2.1 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-client;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-http;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-io;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-security;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-server;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-servlet;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-webapp;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty#jetty-xml;9.4.40.v20210413 from local-m2-cache in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-api;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-client;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-common;9.4.40.v20210413 from central in [default]\n",
      "\torg.jline#jline;3.9.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from local-m2-cache in [default]\n",
      "\torg.ow2.asm#asm;5.0.4 from local-m2-cache in [default]\n",
      "\torg.postgresql#postgresql;42.5.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.32 from local-m2-cache in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.30 from local-m2-cache in [default]\n",
      "\torg.spark-project.spark#unused;1.0.0 from local-m2-cache in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.4 from local-m2-cache in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 by [org.checkerframework#checker-qual;3.5.0] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 by [org.slf4j#slf4j-api;1.7.32] in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 by [org.xerial.snappy#snappy-java;1.1.8.4] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  132  |   10  |   10  |   4   ||  128  |   11  |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: WARNINGS\n",
      "\t\t[NOT FOUND  ] org.apache.commons#commons-math3;3.1.1!commons-math3.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.apache.commons#commons-lang3;3.7!commons-lang3.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/commons/commons-lang3/3.7/commons-lang3-3.7.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.apache.commons#commons-text;1.4!commons-text.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/commons/commons-text/1.4/commons-text-1.4.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.apache.avro#avro;1.7.7!avro.jar(bundle) (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/avro/avro/1.7.7/avro-1.7.7.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.apache.curator#curator-recipes;4.2.0!curator-recipes.jar(bundle) (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/curator/curator-recipes/4.2.0/curator-recipes-4.2.0.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] com.google.code.findbugs#jsr305;3.0.2!jsr305.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.apache.zookeeper#zookeeper;3.5.6!zookeeper.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/zookeeper/zookeeper/3.5.6/zookeeper-3.5.6.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] com.fasterxml.jackson.core#jackson-databind;2.10.5.1!jackson-databind.jar(bundle) (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.10.5.1/jackson-databind-2.10.5.1.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.apache.curator#curator-framework;4.2.0!curator-framework.jar(bundle) (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/curator/curator-framework/4.2.0/curator-framework-4.2.0.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] org.apache.zookeeper#zookeeper-jute;3.5.6!zookeeper-jute.jar (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/org/apache/zookeeper/zookeeper-jute/3.5.6/zookeeper-jute-3.5.6.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] com.fasterxml.jackson.core#jackson-annotations;2.10.5!jackson-annotations.jar(bundle) (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.10.5/jackson-annotations-2.10.5.jar\n",
      "\n",
      "\t\t[NOT FOUND  ] com.fasterxml.jackson.core#jackson-core;2.10.5!jackson-core.jar(bundle) (0ms)\n",
      "\n",
      "\t==== local-m2-cache: tried\n",
      "\n",
      "\t  file:/home/steven/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.10.5/jackson-core-2.10.5.jar\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\t\t::              FAILED DOWNLOADS            ::\n",
      "\n",
      "\t\t:: ^ see resolution messages for details  ^ ::\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\t\t:: com.google.code.findbugs#jsr305;3.0.2!jsr305.jar\n",
      "\n",
      "\t\t:: org.apache.commons#commons-math3;3.1.1!commons-math3.jar\n",
      "\n",
      "\t\t:: org.apache.commons#commons-lang3;3.7!commons-lang3.jar\n",
      "\n",
      "\t\t:: org.apache.commons#commons-text;1.4!commons-text.jar\n",
      "\n",
      "\t\t:: org.apache.avro#avro;1.7.7!avro.jar(bundle)\n",
      "\n",
      "\t\t:: com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar\n",
      "\n",
      "\t\t:: org.apache.zookeeper#zookeeper;3.5.6!zookeeper.jar\n",
      "\n",
      "\t\t:: org.apache.zookeeper#zookeeper-jute;3.5.6!zookeeper-jute.jar\n",
      "\n",
      "\t\t:: org.apache.curator#curator-framework;4.2.0!curator-framework.jar(bundle)\n",
      "\n",
      "\t\t:: org.apache.curator#curator-recipes;4.2.0!curator-recipes.jar(bundle)\n",
      "\n",
      "\t\t:: com.fasterxml.jackson.core#jackson-databind;2.10.5.1!jackson-databind.jar(bundle)\n",
      "\n",
      "\t\t:: com.fasterxml.jackson.core#jackson-annotations;2.10.5!jackson-annotations.jar(bundle)\n",
      "\n",
      "\t\t:: com.fasterxml.jackson.core#jackson-core;2.10.5!jackson-core.jar(bundle)\n",
      "\n",
      "\t\t::::::::::::::::::::::::::::::::::::::::::::::\n",
      "\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      "Exception in thread \"main\" java.lang.RuntimeException: [download failed: com.google.code.findbugs#jsr305;3.0.2!jsr305.jar, download failed: org.apache.commons#commons-math3;3.1.1!commons-math3.jar, download failed: org.apache.commons#commons-lang3;3.7!commons-lang3.jar, download failed: org.apache.commons#commons-text;1.4!commons-text.jar, download failed: org.apache.avro#avro;1.7.7!avro.jar(bundle), download failed: com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar, download failed: org.apache.zookeeper#zookeeper;3.5.6!zookeeper.jar, download failed: org.apache.zookeeper#zookeeper-jute;3.5.6!zookeeper-jute.jar, download failed: org.apache.curator#curator-framework;4.2.0!curator-framework.jar(bundle), download failed: org.apache.curator#curator-recipes;4.2.0!curator-recipes.jar(bundle), download failed: com.fasterxml.jackson.core#jackson-databind;2.10.5.1!jackson-databind.jar(bundle), download failed: com.fasterxml.jackson.core#jackson-annotations;2.10.5!jackson-annotations.jar(bundle), download failed: com.fasterxml.jackson.core#jackson-core;2.10.5!jackson-core.jar(bundle)]\n",
      "\tat org.apache.spark.deploy.SparkSubmitUtils$.resolveMavenCoordinates(SparkSubmit.scala:1447)\n",
      "\tat org.apache.spark.util.DependencyUtils$.resolveMavenDependencies(DependencyUtils.scala:185)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:308)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:898)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1043)\n",
      "\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1052)\n",
      "\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java gateway process exited before sending its port number\n"
     ]
    }
   ],
   "source": [
    "spark_host = \"spark-master\"\n",
    "# spark_host = \"spark-master\"\n",
    "aws_client = creds[\"aws_client\"]\n",
    "aws_secret = creds[\"aws_secret\"]\n",
    "index = 0\n",
    "subreddit = \"technology\"\n",
    "\n",
    "# initialize spark session\n",
    "try:\n",
    "    spark = SparkSession.builder.appName(\"reddit_{}\".format(subreddit)) \\\n",
    "                .master(\"spark://{}:7077\".format(spark_host)) \\\n",
    "                .config(\"spark.scheduler.mode\", \"FAIR\") \\\n",
    "                .config(\"spark.scheduler.allocation.file\", \"file:///opt/workspace/redditStreaming/fairscheduler.xml\") \\\n",
    "                .config(\"spark.executor.memory\", \"4096m\") \\\n",
    "                .config(\"spark.executor.cores\", \"4\") \\\n",
    "                .config(\"spark.streaming.concurrentJobs\", \"4\") \\\n",
    "                .config(\"spark.local.dir\", \"/opt/workspace/tmp/driver/{}/\".format(subreddit)) \\\n",
    "                .config(\"spark.worker.dir\", \"/opt/workspace/tmp/executor/{}/\".format(subreddit)) \\\n",
    "                .config(\"spark.eventLog.enabled\", \"true\") \\\n",
    "                .config(\"spark.eventLog.dir\", \"file:///opt/workspace/events/{}/\".format(subreddit)) \\\n",
    "                .config(\"spark.sql.debug.maxToStringFields\", 1000) \\\n",
    "                .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.1,org.apache.hadoop:hadoop-common:3.3.1,org.apache.hadoop:hadoop-aws:3.3.1,org.apache.hadoop:hadoop-client:3.3.1,io.delta:delta-core_2.12:1.2.1,org.postgresql:postgresql:42.5.0\") \\\n",
    "                .config(\"spark.hadoop.fs.s3a.access.key\", aws_client) \\\n",
    "                .config(\"spark.hadoop.fs.s3a.secret.key\", aws_secret) \\\n",
    "                .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "                .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider') \\\n",
    "                .config('spark.hadoop.fs.s3a.buffer.dir', '/opt/workspace/tmp/blocks') \\\n",
    "                .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "                .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "                .config(\"spark.delta.logStore.class\", \"org.apache.spark.sql.delta.storage.S3SingleDriverLogStore\") \\\n",
    "                .enableHiveSupport() \\\n",
    "                .getOrCreate()\n",
    "\n",
    "    sc = spark.sparkContext\n",
    "    # .config('spark.hadoop.fs.s3a.fast.upload.buffer', 'bytebuffer') \\\n",
    "\n",
    "    sc.setLogLevel('WARN')\n",
    "    sc.setLocalProperty(\"spark.scheduler.pool\", \"pool{}\".format(str(index)))\n",
    "    # sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsAccessKeyId\", aws_client)\n",
    "    # sc._jsc.hadoopConfiguration().set(\"fs.s3a.awsSecretAccessKey\", aws_secret)\n",
    "    # sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-2.amazonaws.com\")\n",
    "    print(\"created spark successfully\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read clean df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_spark_jdbc(subreddit):\n",
    "    \n",
    "    df = spark.read.format(\"delta\").option(\"header\", True).load(\"s3a://reddit-streaming-stevenhurwitt/\" + subreddit + \"_clean\")\n",
    "\n",
    "    with open(\"config.yaml\", \"r\") as g:\n",
    "        config = yaml.safe_load(g)\n",
    "        g.close()\n",
    "\n",
    "    connect_str = \"jdbc:postgresql://{}:5432/postgres\".format(config[\"postgres_host\"])\n",
    "\n",
    "    try:\n",
    "        df.write.format(\"jdbc\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .option(\"url\", connect_str) \\\n",
    "            .option(\"dbtable\", \"public.{}\".format(subreddit)) \\\n",
    "            .option(\"user\", config[\"postgres_user\"]) \\\n",
    "            .option(\"password\", config[\"postgres_password\"]) \\\n",
    "            .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "            .save()\n",
    "\n",
    "        print(\"wrote df to postgresql table.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote df to postgresql table.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/09 06:30:47 WARN HeartbeatReceiver: Removing executor 0 with no recent heartbeats: 1182766 ms exceeds timeout 120000 ms\n",
      "22/12/09 06:30:47 ERROR TaskSchedulerImpl: Lost executor 0 on 172.19.0.7: Executor heartbeat timed out after 1182766 ms\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_16 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_25 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_13 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_47 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_5 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_22 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_35 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_43 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_0 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_17 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_18 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_5 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_7 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_46 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_33 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_1 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_21 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_31 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_14 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_30 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_3 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_14 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_44 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_34 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_6 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_12 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_16 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_31 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_10 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_22 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_28 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_36 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_19 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_48 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_41 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_46 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_41 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_38 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_21 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_14 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_23 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_29 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_0 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_45 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_42 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_19 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_31 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_42 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_7 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_37 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_18 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_26 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_34 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_4 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_40 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_47 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_1 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_16 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_38 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_23 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_7 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_17 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_26 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_35 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_2 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_13 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_49 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_26 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_9 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_12 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_47 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_22 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_1 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_9 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_11 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_36 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_11 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_31 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_31 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_15 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_15 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_30 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_30 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_11 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_22 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_20 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_13 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_39 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_20 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_42 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_37 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_20 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_32 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_21 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_31 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_28 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_30 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_0 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_34 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_32 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_15 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_32 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_22 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_34 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_5 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_32 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_39 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_41 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_13 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_3 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_43 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_3 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_23 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_1 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_8 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_12 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_29 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_10 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_20 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_48 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_37 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_26 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_44 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_29 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_34 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_8 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_48 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_8 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_8 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_3 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_38 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_29 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_6 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_44 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_17 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_45 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_28 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_18 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_331_2 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_45 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_25 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_10 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_9 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_6 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_43 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_49 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_24 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_1 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_42 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_37 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_9 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_46 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_37 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_5 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_5 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_44 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_27 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_186_24 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_23 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_273_4 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_46 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_43 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_157_7 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_39 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_244_36 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_17 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_302_10 !\n",
      "22/12/09 06:30:47 WARN BlockManagerMasterEndpoint: No more replicas available for rdd_215_25 !\n",
      "22/12/09 08:02:33 WARN HeartbeatReceiver: Removing executor 2 with no recent heartbeats: 3335033 ms exceeds timeout 120000 ms\n",
      "22/12/09 08:02:33 ERROR TaskSchedulerImpl: Lost executor 2 on 172.19.0.7: Executor heartbeat timed out after 3335033 ms\n"
     ]
    }
   ],
   "source": [
    "subreddit = \"BikiniBottomTwitter\"\n",
    "write_spark_jdbc(subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/09 04:35:15 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = spark.read.format(\"delta\").option(\"header\", True).load(\"s3a://reddit-streaming-stevenhurwitt/\" + subreddit + \"_clean\")\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"can't run at same time as streaming job...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/pyspark/sql/pandas/conversion.py:202: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[column_name] = series\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author_fullname</th>\n",
       "      <th>saved</th>\n",
       "      <th>mod_reason_title</th>\n",
       "      <th>gilded</th>\n",
       "      <th>clicked</th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>...</th>\n",
       "      <th>url</th>\n",
       "      <th>subreddit_subscribers</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>num_crossposts</th>\n",
       "      <th>media</th>\n",
       "      <th>is_video</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaT</td>\n",
       "      <td>technology</td>\n",
       "      <td></td>\n",
       "      <td>t2_dz54148i</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>How to combat the unethical and costly use of ...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>...</td>\n",
       "      <td>https://theconversation.com/how-to-combat-the-...</td>\n",
       "      <td>12257109</td>\n",
       "      <td>2022-06-23 12:19:43.780864</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaT</td>\n",
       "      <td>technology</td>\n",
       "      <td>Hello Reddit! In 2015, I left the advertising ...</td>\n",
       "      <td>t2_s6k8l</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>I'm Adam Roe, Founder, CEO, and Product Archit...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.reddit.com/r/technology/comments/v...</td>\n",
       "      <td>12258760</td>\n",
       "      <td>2022-06-23 17:01:35.214592</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaT</td>\n",
       "      <td>technology</td>\n",
       "      <td></td>\n",
       "      <td>t2_8xdyr63g</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Instagram is testing an AI tool that verifies ...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.theverge.com/2022/6/23/23179752/in...</td>\n",
       "      <td>12257384</td>\n",
       "      <td>2022-06-23 13:20:07.659520</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaT</td>\n",
       "      <td>technology</td>\n",
       "      <td></td>\n",
       "      <td>t2_95cwi5om</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>MIT robotics engineers are accelerating robot ...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.pcgamer.com/mit-robotics-engineers...</td>\n",
       "      <td>12260832</td>\n",
       "      <td>2022-06-23 23:53:11.276544</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaT</td>\n",
       "      <td>technology</td>\n",
       "      <td></td>\n",
       "      <td>t2_e8nv4</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Netflix Layoffs Continue as 300 More Employees...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>...</td>\n",
       "      <td>https://variety.com/2022/tv/news/netflix-layof...</td>\n",
       "      <td>12258902</td>\n",
       "      <td>2022-06-23 17:48:33.786880</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc   subreddit  \\\n",
       "0             NaT  technology   \n",
       "1             NaT  technology   \n",
       "2             NaT  technology   \n",
       "3             NaT  technology   \n",
       "4             NaT  technology   \n",
       "\n",
       "                                            selftext author_fullname  saved  \\\n",
       "0                                                        t2_dz54148i  False   \n",
       "1  Hello Reddit! In 2015, I left the advertising ...        t2_s6k8l  False   \n",
       "2                                                        t2_8xdyr63g  False   \n",
       "3                                                        t2_95cwi5om  False   \n",
       "4                                                           t2_e8nv4  False   \n",
       "\n",
       "  mod_reason_title  gilded  clicked  \\\n",
       "0             None       0    False   \n",
       "1             None       0    False   \n",
       "2             None       0    False   \n",
       "3             None       0    False   \n",
       "4             None       0    False   \n",
       "\n",
       "                                               title subreddit_name_prefixed  \\\n",
       "0  How to combat the unethical and costly use of ...            r/technology   \n",
       "1  I'm Adam Roe, Founder, CEO, and Product Archit...            r/technology   \n",
       "2  Instagram is testing an AI tool that verifies ...            r/technology   \n",
       "3  MIT robotics engineers are accelerating robot ...            r/technology   \n",
       "4  Netflix Layoffs Continue as 300 More Employees...            r/technology   \n",
       "\n",
       "   ...                                                url  \\\n",
       "0  ...  https://theconversation.com/how-to-combat-the-...   \n",
       "1  ...  https://www.reddit.com/r/technology/comments/v...   \n",
       "2  ...  https://www.theverge.com/2022/6/23/23179752/in...   \n",
       "3  ...  https://www.pcgamer.com/mit-robotics-engineers...   \n",
       "4  ...  https://variety.com/2022/tv/news/netflix-layof...   \n",
       "\n",
       "   subreddit_subscribers                created_utc  num_crossposts  media  \\\n",
       "0               12257109 2022-06-23 12:19:43.780864               0   None   \n",
       "1               12258760 2022-06-23 17:01:35.214592               0   None   \n",
       "2               12257384 2022-06-23 13:20:07.659520               0   None   \n",
       "3               12260832 2022-06-23 23:53:11.276544               1   None   \n",
       "4               12258902 2022-06-23 17:48:33.786880               0   None   \n",
       "\n",
       "  is_video        date  year  month day  \n",
       "0    False  2022-06-23  2022      6  23  \n",
       "1    False  2022-06-23  2022      6  23  \n",
       "2    False  2022-06-23  2022      6  23  \n",
       "3    False  2022-06-23  2022      6  23  \n",
       "4    False  2022-06-23  2022      6  23  \n",
       "\n",
       "[5 rows x 103 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = df.toPandas()\n",
    "pandas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write to postgres table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", \"r\") as g:\n",
    "    config = yaml.safe_load(g)\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(host = config[\"postgres_host\"], user = config[\"postgres_user\"], password = config[\"postgres_password\"], database=\"postgres\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:==================================================>       (7 + 1) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote df to postgresql table.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "connect_str = \"jdbc:postgresql://{}:5432/postgres\".format(config[\"postgres_host\"])\n",
    "\n",
    "try:\n",
    "    df.write.format(\"jdbc\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .option(\"url\", connect_str) \\\n",
    "        .option(\"dbtable\", \"public.{}\".format(subreddit)) \\\n",
    "        .option(\"user\", config[\"postgres_user\"]) \\\n",
    "        .option(\"password\", config[\"postgres_password\"]) \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .save()\n",
    "\n",
    "    print(\"wrote df to postgresql table.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stop spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession does not exist in the JVM\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
