{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9dc4867",
   "metadata": {},
   "source": [
    "# Read Delta Tables from S3\n",
    "\n",
    "This notebook reads reddit data stored in Delta format on S3, unions the data from multiple subreddits, and sorts by most recent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /opt/workspace\n",
      "Found credentials at: redditStreaming/src/reddit/creds.json\n",
      "Found config at: redditStreaming/config.yaml\n",
      "Subreddits to process: ['technology', 'ProgrammerHumor', 'news', 'worldnews']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_unixtime\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "# Function to read credentials and config\n",
    "def find_file(filename, search_paths):\n",
    "    # Check specific paths first\n",
    "    for path in search_paths:\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    \n",
    "    # Walk up from CWD\n",
    "    curr = os.getcwd()\n",
    "    while True:\n",
    "        f = os.path.join(curr, filename)\n",
    "        if os.path.exists(f):\n",
    "            return f\n",
    "        parent = os.path.dirname(curr)\n",
    "        if parent == curr:\n",
    "            break\n",
    "        curr = parent\n",
    "    return None\n",
    "\n",
    "def read_config_creds():\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Creds paths to search\n",
    "    creds_paths = [\n",
    "        \"creds.json\",\n",
    "        \"redditStreaming/creds.json\",\n",
    "        \"redditStreaming/src/reddit/creds.json\",\n",
    "        \"/home/steven/reddit-streaming/creds.json\",\n",
    "        \"/home/steven/reddit-streaming/redditStreaming/creds.json\",\n",
    "        \"/home/steven/reddit-streaming/redditStreaming/src/reddit/creds.json\",\n",
    "        \"/opt/workspace/creds.json\",\n",
    "        \"/opt/workspace/redditStreaming/creds.json\"\n",
    "    ]\n",
    "    \n",
    "    creds_file = find_file(\"creds.json\", creds_paths)\n",
    "    if not creds_file:\n",
    "         raise FileNotFoundError(\"Could not find creds.json in search paths or parent directories.\")\n",
    "    \n",
    "    print(f\"Found credentials at: {creds_file}\")\n",
    "    with open(creds_file, \"r\") as f:\n",
    "        creds = json.load(f)\n",
    "\n",
    "    # Config paths to search\n",
    "    config_paths = [\n",
    "        \"config.yaml\",\n",
    "        \"redditStreaming/config.yaml\",\n",
    "        \"redditStreaming/src/reddit/config.yaml\",\n",
    "        \"/home/steven/reddit-streaming/config.yaml\",\n",
    "        \"/home/steven/reddit-streaming/redditStreaming/config.yaml\",\n",
    "        \"/home/steven/reddit-streaming/redditStreaming/src/reddit/config.yaml\",\n",
    "        \"/opt/workspace/redditStreaming/config.yaml\"\n",
    "    ]\n",
    "    \n",
    "    config_file = find_file(\"config.yaml\", config_paths)\n",
    "    if not config_file:\n",
    "         print(\"Warning: Could not find config.yaml, using defaults or trying alternate locations.\")\n",
    "         # Fallback search if needed, but for now we raise error if strictly required\n",
    "         # In the original code config was critical for bucket/spark host, but here we need subreddits.\n",
    "         pass\n",
    "         \n",
    "    if config_file:\n",
    "        print(f\"Found config at: {config_file}\")\n",
    "        with open(config_file, \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "    else:\n",
    "        # Fallback config if file missing\n",
    "        config = {\"subreddit\": [\"technology\", \"ProgrammerHumor\", \"news\", \"worldnews\"]}\n",
    "        print(\"Using default configuration for subreddits.\")\n",
    "        \n",
    "    return creds, config\n",
    "\n",
    "creds, config = read_config_creds()\n",
    "\n",
    "# Extract values\n",
    "aws_client = creds.get(\"aws_client\")\n",
    "aws_secret = creds.get(\"aws_secret\")\n",
    "subreddits = config.get(\"subreddit\", [\"technology\", \"ProgrammerHumor\", \"news\", \"worldnews\"])\n",
    "bucket_name = \"reddit-streaming-stevenhurwitt-2\" \n",
    "\n",
    "print(f\"Subreddits to process: {subreddits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1746c5",
   "metadata": {},
   "source": [
    "## start spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296bd736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/venv/lib/python3.9/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.hadoop#hadoop-common added as a dependency\n",
      "org.apache.hadoop#hadoop-aws added as a dependency\n",
      "org.apache.hadoop#hadoop-client added as a dependency\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-5a1e83e6-95a5-4c9c-9bc4-55ab37e182c8;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.3 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.3 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.5 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-common;3.3.1 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-protobuf_3_7;1.1.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-annotations;3.3.1 in central\n",
      "\tfound org.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 in central\n",
      "\tfound com.google.guava#guava;27.0-jre in central\n",
      "\tfound com.google.guava#failureaccess;1.0 in central\n",
      "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
      "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
      "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
      "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
      "\tfound commons-cli#commons-cli;1.2 in central\n",
      "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
      "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
      "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
      "\tfound commons-codec#commons-codec;1.11 in central\n",
      "\tfound commons-io#commons-io;2.8.0 in central\n",
      "\tfound commons-net#commons-net;3.6 in central\n",
      "\tfound commons-collections#commons-collections;3.2.2 in central\n",
      "\tfound javax.servlet#javax.servlet-api;3.1.0 in central\n",
      "\tfound org.eclipse.jetty#jetty-server;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-http;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-io;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-servlet;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-security;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-webapp;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-xml;9.4.40.v20210413 in central\n",
      "\tfound com.sun.jersey#jersey-core;1.19 in central\n",
      "\tfound javax.ws.rs#jsr311-api;1.1.1 in central\n",
      "\tfound com.sun.jersey#jersey-servlet;1.19 in central\n",
      "\tfound com.sun.jersey#jersey-server;1.19 in central\n",
      "\tfound com.sun.jersey#jersey-json;1.19 in central\n",
      "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
      "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.2.11 in central\n",
      "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
      "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
      "\tfound log4j#log4j;1.2.17 in central\n",
      "\tfound commons-beanutils#commons-beanutils;1.9.4 in central\n",
      "\tfound org.apache.commons#commons-configuration2;2.1.1 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.7 in central\n",
      "\tfound org.apache.commons#commons-text;1.4 in central\n",
      "\tfound org.slf4j#slf4j-log4j12;1.7.30 in central\n",
      "\tfound org.apache.avro#avro;1.7.7 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.3 in central\n",
      "\tfound org.apache.commons#commons-compress;1.19 in central\n",
      "\tfound com.google.re2j#re2j;1.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound com.google.code.gson#gson;2.2.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-auth;3.3.1 in central\n",
      "\tfound com.nimbusds#nimbus-jose-jwt;9.8.1 in central\n",
      "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
      "\tfound net.minidev#json-smart;2.4.2 in central\n",
      "\tfound net.minidev#accessors-smart;2.4.2 in central\n",
      "\tfound org.ow2.asm#asm;5.0.4 in central\n",
      "\tfound org.apache.zookeeper#zookeeper;3.5.6 in central\n",
      "\tfound org.apache.zookeeper#zookeeper-jute;3.5.6 in central\n",
      "\tfound org.apache.yetus#audience-annotations;0.5.0 in central\n",
      "\tfound org.apache.curator#curator-framework;4.2.0 in central\n",
      "\tfound org.apache.curator#curator-client;4.2.0 in central\n",
      "\tfound org.apache.kerby#kerb-simplekdc;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-client;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-config;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-core;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-pkix;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-asn1;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-util;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-common;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-crypto;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-util;1.0.1 in central\n",
      "\tfound org.apache.kerby#token-provider;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-admin;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-server;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerb-identity;1.0.1 in central\n",
      "\tfound org.apache.kerby#kerby-xdr;1.0.1 in central\n",
      "\tfound com.jcraft#jsch;0.1.55 in central\n",
      "\tfound org.apache.curator#curator-recipes;4.2.0 in central\n",
      "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-databind;2.10.5.1 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-annotations;2.10.5 in central\n",
      "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in central\n",
      "\tfound org.codehaus.woodstox#stax2-api;4.2.1 in central\n",
      "\tfound com.fasterxml.woodstox#woodstox-core;5.3.0 in central\n",
      "\tfound dnsjava#dnsjava;2.1.7 in central\n",
      "\tfound jakarta.activation#jakarta.activation-api;1.2.1 in central\n",
      "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-aws;3.3.1 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.901 in central\n",
      "\tfound org.wildfly.openssl#wildfly-openssl;1.0.7.Final in central\n",
      "\tfound org.apache.hadoop#hadoop-client;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-hdfs-client;3.3.1 in central\n",
      "\tfound com.squareup.okhttp#okhttp;2.7.5 in central\n",
      "\tfound com.squareup.okio#okio;1.6.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-api;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-client;3.3.1 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-client;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty#jetty-client;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-common;9.4.40.v20210413 in central\n",
      "\tfound org.eclipse.jetty.websocket#websocket-api;9.4.40.v20210413 in central\n",
      "\tfound org.jline#jline;3.9.0 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-core;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-yarn-common;3.3.1 in central\n",
      "\tfound com.sun.jersey#jersey-client;1.19 in central\n",
      "\tfound com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 in central\n",
      "\tfound jakarta.xml.bind#jakarta.xml.bind-api;2.3.2 in central\n",
      "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 in central\n",
      "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-jobclient;3.3.1 in central\n",
      "\tfound org.apache.hadoop#hadoop-mapreduce-client-common;3.3.1 in central\n",
      "\tfound io.delta#delta-spark_2.12;3.2.0 in central\n",
      "\tfound io.delta#delta-storage;3.2.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      "\tfound org.postgresql#postgresql;42.5.0 in central\n",
      "\tfound org.checkerframework#checker-qual;3.5.0 in central\n",
      ":: resolution report :: resolve 39971ms :: artifacts dl 1324ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.901 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-annotations;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.core#jackson-databind;2.10.5.1 from central in [default]\n",
      "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 from central in [default]\n",
      "\tcom.fasterxml.woodstox#woodstox-core;5.3.0 from central in [default]\n",
      "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.2.4 from central in [default]\n",
      "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
      "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
      "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
      "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcom.google.re2j#re2j;1.1 from central in [default]\n",
      "\tcom.jcraft#jsch;0.1.55 from central in [default]\n",
      "\tcom.nimbusds#nimbus-jose-jwt;9.8.1 from central in [default]\n",
      "\tcom.squareup.okhttp#okhttp;2.7.5 from central in [default]\n",
      "\tcom.squareup.okio#okio;1.6.0 from central in [default]\n",
      "\tcom.sun.jersey#jersey-client;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-core;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-json;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-server;1.19 from central in [default]\n",
      "\tcom.sun.jersey#jersey-servlet;1.19 from central in [default]\n",
      "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.3 from central in [default]\n",
      "\tcommons-beanutils#commons-beanutils;1.9.4 from central in [default]\n",
      "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
      "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
      "\tcommons-collections#commons-collections;3.2.2 from central in [default]\n",
      "\tcommons-io#commons-io;2.8.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tcommons-net#commons-net;3.6 from central in [default]\n",
      "\tdnsjava#dnsjava;2.1.7 from central in [default]\n",
      "\tio.delta#delta-spark_2.12;3.2.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.2.0 from central in [default]\n",
      "\tjakarta.activation#jakarta.activation-api;1.2.1 from central in [default]\n",
      "\tjakarta.xml.bind#jakarta.xml.bind-api;2.3.2 from central in [default]\n",
      "\tjavax.servlet#javax.servlet-api;3.1.0 from central in [default]\n",
      "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
      "\tjavax.ws.rs#jsr311-api;1.1.1 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.2.11 from central in [default]\n",
      "\tlog4j#log4j;1.2.17 from central in [default]\n",
      "\tnet.minidev#accessors-smart;2.4.2 from central in [default]\n",
      "\tnet.minidev#json-smart;2.4.2 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\torg.apache.avro#avro;1.7.7 from central in [default]\n",
      "\torg.apache.commons#commons-compress;1.19 from central in [default]\n",
      "\torg.apache.commons#commons-configuration2;2.1.1 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.7 from central in [default]\n",
      "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.commons#commons-text;1.4 from central in [default]\n",
      "\torg.apache.curator#curator-client;4.2.0 from central in [default]\n",
      "\torg.apache.curator#curator-framework;4.2.0 from central in [default]\n",
      "\torg.apache.curator#curator-recipes;4.2.0 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-annotations;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-auth;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-aws;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-hdfs-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-core;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-mapreduce-client-jobclient;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-api;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-client;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-yarn-common;3.3.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-guava;1.1.1 from central in [default]\n",
      "\torg.apache.hadoop.thirdparty#hadoop-shaded-protobuf_3_7;1.1.1 from central in [default]\n",
      "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
      "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
      "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-admin;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-client;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-common;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-core;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-crypto;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-identity;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-server;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-simplekdc;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerb-util;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-asn1;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-config;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-pkix;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-util;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#kerby-xdr;1.0.1 from central in [default]\n",
      "\torg.apache.kerby#token-provider;1.0.1 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.3 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.3 from central in [default]\n",
      "\torg.apache.yetus#audience-annotations;0.5.0 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper;3.5.6 from central in [default]\n",
      "\torg.apache.zookeeper#zookeeper-jute;3.5.6 from central in [default]\n",
      "\torg.checkerframework#checker-qual;3.5.0 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
      "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
      "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
      "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
      "\torg.codehaus.woodstox#stax2-api;4.2.1 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-client;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-http;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-io;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-security;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-server;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-servlet;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-util-ajax;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-webapp;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty#jetty-xml;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-api;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-client;9.4.40.v20210413 from central in [default]\n",
      "\torg.eclipse.jetty.websocket#websocket-common;9.4.40.v20210413 from central in [default]\n",
      "\torg.jline#jline;3.9.0 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.ow2.asm#asm;5.0.4 from central in [default]\n",
      "\torg.postgresql#postgresql;42.5.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.slf4j#slf4j-log4j12;1.7.30 from central in [default]\n",
      "\torg.wildfly.openssl#wildfly-openssl;1.0.7.Final from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.5 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 by [com.google.code.findbugs#jsr305;3.0.2] in [default]\n",
      "\torg.checkerframework#checker-qual;2.5.2 by [org.checkerframework#checker-qual;3.5.0] in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.30 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.8.2 by [org.xerial.snappy#snappy-java;1.1.10.5] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |  131  |   0   |   0   |   4   ||  127  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-5a1e83e6-95a5-4c9c-9bc4-55ab37e182c8\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 127 already retrieved (0kB/540ms)\n",
      "26/01/23 19:52:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "26/01/23 19:53:29 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "26/01/23 19:53:29 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "26/01/23 19:53:38 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "26/01/23 19:53:38 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "26/01/23 19:53:48 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "26/01/23 19:53:48 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "26/01/23 19:53:58 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "26/01/23 19:53:58 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/venv/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/opt/venv/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "26/01/23 19:54:08 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.SparkThreadUtils$.awaitResult(SparkThreadUtils.scala:56)\n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:310)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:101)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:85)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:80)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:642)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1223)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:295)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1928)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)\n",
      "\tat java.base/java.util.concurrent.FutureTask.runAndReset(FutureTask.java:305)\n",
      "\tat java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:305)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n",
      "Caused by: java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\t... 3 more\n",
      "26/01/23 19:54:08 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException: Cannot invoke \"org.apache.spark.storage.BlockManagerId.executorId()\" because \"idWithoutTopologyInfo\" is null\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:677)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:133)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:840)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize Spark Session with Delta and S3 support\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Using the same jars as in the main application\u001b[39;00m\n\u001b[1;32m      3\u001b[0m extra_jar_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morg.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3,org.apache.hadoop:hadoop-common:3.3.1,org.apache.hadoop:hadoop-aws:3.3.1,org.apache.hadoop:hadoop-client:3.3.1,io.delta:delta-spark_2.12:3.2.0,org.postgresql:postgresql:42.5.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRedditDeltaRead\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal[*]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.jars.packages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_jar_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.extensions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mio.delta.sql.DeltaSparkSessionExtension\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.sql.catalog.spark_catalog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.spark.sql.delta.catalog.DeltaCatalog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.hadoop.fs.s3a.access.key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maws_client\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.hadoop.fs.s3a.secret.key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maws_secret\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspark.hadoop.fs.s3a.impl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.hadoop.fs.s3a.S3AFileSystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspark.hadoop.fs.s3a.aws.credentials.provider\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morg.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m spark\u001b[38;5;241m.\u001b[39msparkContext\u001b[38;5;241m.\u001b[39msetLogLevel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpark Session created.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/pyspark/sql/session.py:497\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    495\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    500\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/pyspark/context.py:515\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/pyspark/context.py:203\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    201\u001b[0m SparkContext\u001b[38;5;241m.\u001b[39m_ensure_initialized(\u001b[38;5;28mself\u001b[39m, gateway\u001b[38;5;241m=\u001b[39mgateway, conf\u001b[38;5;241m=\u001b[39mconf)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mappName\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparkHome\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpyFiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatchSize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjsc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprofiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m        \u001b[49m\u001b[43mudf_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_profiler_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# If an error occurs, clean up in order to allow future SparkContext creation:\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/pyspark/context.py:296\u001b[0m, in \u001b[0;36mSparkContext._do_init\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, jsc, profiler_cls, udf_profiler_cls, memory_profiler_cls)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPYTHONHASHSEED\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Create the Java SparkContext through Py4J\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc \u001b[38;5;241m=\u001b[39m jsc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize_context\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;66;03m# Reset the SparkConf to the one actually used by the SparkContext in JVM.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conf \u001b[38;5;241m=\u001b[39m SparkConf(_jconf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsc\u001b[38;5;241m.\u001b[39msc()\u001b[38;5;241m.\u001b[39mconf())\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/pyspark/context.py:421\u001b[0m, in \u001b[0;36mSparkContext._initialize_context\u001b[0;34m(self, jconf)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03mInitialize SparkContext in function to allow subclass specific initialization\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJavaSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjconf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/py4j/java_gateway.py:1586\u001b[0m, in \u001b[0;36mJavaClass.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1578\u001b[0m args_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m   1579\u001b[0m     [get_command_part(arg, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m new_args])\n\u001b[1;32m   1581\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCONSTRUCTOR_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1582\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_command_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1583\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1584\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1586\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1587\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1588\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gateway_client, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fqn)\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/opt/venv/lib/python3.9/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session with Delta and S3 support\n",
    "# Using the same jars as in the main application\n",
    "extra_jar_list = \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.3,org.apache.hadoop:hadoop-common:3.3.1,org.apache.hadoop:hadoop-aws:3.3.1,org.apache.hadoop:hadoop-client:3.3.1,io.delta:delta-spark_2.12:3.2.0,org.postgresql:postgresql:42.5.0\"\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RedditDeltaRead\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", extra_jar_list) \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.hadoop.fs.s3a.access.key\", aws_client) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.secret.key\", aws_secret) \\\n",
    "    .config(\"spark.hadoop.fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\") \\\n",
    "    .config('spark.hadoop.fs.s3a.aws.credentials.provider', 'org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "print(\"Spark Session created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317ec9e",
   "metadata": {},
   "source": [
    "## read data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c42bf89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read from: s3a://reddit-streaming-stevenhurwitt-2/technology\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for technology. Count: 1841\n",
      "Attempting to read from: s3a://reddit-streaming-stevenhurwitt-2/ProgrammerHumor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for ProgrammerHumor. Count: 1796\n",
      "Attempting to read from: s3a://reddit-streaming-stevenhurwitt-2/news\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for news. Count: 1203\n",
      "Attempting to read from: s3a://reddit-streaming-stevenhurwitt-2/worldnews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 331:===================================================>   (47 + 3) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read data for worldnews. Count: 2266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read Delta tables for each subreddit\n",
    "dfs = []\n",
    "\n",
    "for sub in subreddits:\n",
    "    path = f\"s3a://{bucket_name}/{sub}\"\n",
    "    print(f\"Attempting to read from: {path}\")\n",
    "    try:\n",
    "        # Read Delta table\n",
    "        df = spark.read.format(\"delta\").load(path)\n",
    "        dfs.append(df)\n",
    "        print(f\"Successfully read data for {sub}. Count: {df.count()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {sub} (might not exist yet): {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08400cd",
   "metadata": {},
   "source": [
    "## union and sort dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5360ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------+\n",
      "|subreddit      |created_time       |title                                                                                                                                                                                                   |score|author              |\n",
      "+---------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------+\n",
      "|worldnews      |2026-01-23 04:43:44|EU leaders seek to preserve ties with US                                                                                                                                                                |1    |pritam_ram          |\n",
      "|worldnews      |2026-01-23 04:18:08|Trumps NATO comments spark outrage from Canadian veterans                                                                                                                                              |3    |an_old_geek         |\n",
      "|worldnews      |2026-01-23 04:07:28|UK avoids signing up to Board of Peace amid concerns over Russia                                                                                                                                        |1    |stikkit2em          |\n",
      "|worldnews      |2026-01-23 04:03:12|/r/WorldNews Live Thread: Russian Invasion of Ukraine Day 1429, Part 1 (Thread #1576)                                                                                                                   |2    |WorldNewsMods       |\n",
      "|technology     |2026-01-23 03:33:20|Underground Resistance Aims To Sabotage AI With Poisoned Data                                                                                                                                           |1    |RNSAFFN             |\n",
      "|ProgrammerHumor|2026-01-23 03:33:20|unusedDockerCrapGoYeet                                                                                                                                                                                  |1    |TxTechnician        |\n",
      "|worldnews      |2026-01-23 03:31:12|Trump sparks anger with claim Nato troops avoided Afghanistan front line                                                                                                                                |1    |dtta8               |\n",
      "|news           |2026-01-23 03:31:12|Minnesota Elementary School Sends Urgent Message as ICE Sends Flyers Offering Food Support to Families                                                                                                  |1    |speedythefirst      |\n",
      "|technology     |2026-01-23 03:29:04|Hundreds set to be laid from Meta's Reality Labs division                                                                                                                                               |1    |Adventurous_Row3305 |\n",
      "|worldnews      |2026-01-23 03:20:32|U.S. envoy pledges support for Taiwan defense industry, cites new ammo test range                                                                                                                       |1    |Hob-999             |\n",
      "|technology     |2026-01-23 03:12:00|Intel puts consumer chip production on back burner as datacenters make a run on Xeons                                                                                                                   |1    |Logical_Welder3467  |\n",
      "|technology     |2026-01-23 03:09:52|Palmer Luckey says the coolest thing about Anduril expanding to Long Beach is the fighter jets                                                                                                          |1    |Logical_Welder3467  |\n",
      "|worldnews      |2026-01-23 03:03:28|EU Plans to Unfreeze Trade Deal With US and Vote on Ratification                                                                                                                                        |0    |Real-Repair-1825    |\n",
      "|technology     |2026-01-23 02:54:56|Pro-government editors wiped Iran rights abuses from Wikipedia - watchdog                                                                                                                               |2    |CyberBerserk        |\n",
      "|worldnews      |2026-01-23 02:50:40|Digital liberation: EU Parliament calls for detachment from US tech giants                                                                                                                              |1    |RollSafer           |\n",
      "|technology     |2026-01-23 02:50:40|Digital liberation: EU Parliament calls for detachment from US tech giants                                                                                                                              |2    |mepper              |\n",
      "|worldnews      |2026-01-23 02:37:52|Israel attacks Lebanon                                                                                                                                                                                  |3    |New_fan22           |\n",
      "|worldnews      |2026-01-23 02:12:16|Have you seen this child? Lia Grace Skeete                                                                                                                                                              |1    |Business_Claim_5689 |\n",
      "|worldnews      |2026-01-23 02:08:00|Today, January 22, 2026 the US completes withdrawal from World Health Organization                                                                                                                      |0    |MoralLogs           |\n",
      "|technology     |2026-01-23 02:08:00|Overrun with AI slop, cURL scraps bug bounties to ensure \"intact mental health\"                                                                                                                         |1    |moeka_8962          |\n",
      "|worldnews      |2026-01-23 02:05:52|Trump says he is withdrawing Canada's invitation to Board of Peace                                                                                                                                      |0    |Inevitable_Fuel7244 |\n",
      "|technology     |2026-01-23 02:05:52|Amazon plans thousands more corporate job cuts next week, sources say                                                                                                                                   |1    |joe4942             |\n",
      "|news           |2026-01-23 01:59:28|Bay Area software rep. lost $176K of savings after accepting remote job she thought to be with FB                                                                                                       |0    |PizzaDelResistance  |\n",
      "|technology     |2026-01-23 01:59:28|Bay Area software rep. lost $176K of savings after accepting remote job she thought to be with Facebook                                                                                                 |2    |Sandstorm400        |\n",
      "|worldnews      |2026-01-23 01:48:48|US and China sign off on TikTok deal                                                                                                                                                                    |1    |UpstairsBumblebee446|\n",
      "|worldnews      |2026-01-23 01:38:08|Greenland and Denmark say sovereignty red line after latest Trump remarks                                                                                                                             |2    |Common_Caramel_4078 |\n",
      "|worldnews      |2026-01-23 01:36:00|Trump says 'massive armada' heading towards Iran as US military assets move                                                                                                                             |1    |ewzetf              |\n",
      "|technology     |2026-01-23 01:36:00|US and China finalizes Tiktok Deal                                                                                                                                                                      |1    |raydebapratim1      |\n",
      "|technology     |2026-01-23 01:23:12|TikTok Strikes Deal to Create New U.S. Entity and Loosen Apps Ties to China                                                                                                                            |1    |vriska1             |\n",
      "|news           |2026-01-23 01:16:48|Election denier, former Jan. 6 officer clash during Jack Smith House hearing                                                                                                                            |1    |ewzetf              |\n",
      "|worldnews      |2026-01-23 01:14:40|US officially leaves World Health Organization                                                                                                                                                          |3    |Obvious-Peanut4406  |\n",
      "|news           |2026-01-23 01:14:40|Renee Good was shot in the head, autopsy commissioned by her family finds                                                                                                                               |1    |ewzetf              |\n",
      "|news           |2026-01-23 01:14:40|Renee Good was shot in the head, autopsy commissioned by her family finds                                                                                                                               |135  |ewzetf              |\n",
      "|worldnews      |2026-01-23 01:10:24|Tiktok deal signed between US and China after months of negotiation                                                                                                                                     |1    |raydebapratim1      |\n",
      "|technology     |2026-01-23 01:08:16|Judge orders stop to FBI search of devices seized from Washington Post reporter Hannah Natanson | Order says govt must stop search while court reviews Washington Post motions.                        |1    |ControlCAD          |\n",
      "|worldnews      |2026-01-23 00:55:28|Bessent: U.S. Concerned Over Denmarks Forced Sterilization of Greenlanders                                                                                                                             |3    |Currency_Anxious    |\n",
      "|technology     |2026-01-23 00:55:28|Maybe VR Doesnt Need Meta After All                                                                                                                                                                    |1    |dapperlemon         |\n",
      "|technology     |2026-01-23 00:44:48|AI Fools Itself: Top Chatbots Dont Recognize AI-Generated Videos                                                                                                                                       |1    |ubcstaffer123       |\n",
      "|worldnews      |2026-01-23 00:42:40|Trump says he will meet Ukraines Zelenskiy as he claims a deal is reasonably close                                                                                                                   |1    |MoralLogs           |\n",
      "|news           |2026-01-23 00:42:40|US officially exits World Health Organization                                                                                                                                                           |1    |pwdrums             |\n",
      "|worldnews      |2026-01-23 00:34:08|Trump under fire for claiming NATO allies avoided Afghanistan frontline                                                                                                                                 |2    |kiyomoris           |\n",
      "|news           |2026-01-23 00:27:44|Fridays 'ICE Out of Minnesota' day is a general strike. Heres what that means                                                                                                                         |9    |smkmn13             |\n",
      "|technology     |2026-01-23 00:19:12|Amazon plans second round of corporate job cuts next week, Reuters reports                                                                                                                              |1    |lurker_bee          |\n",
      "|ProgrammerHumor|2026-01-23 00:08:32|the2AMCure                                                                                                                                                                                              |2    |ArjunReddyDeshmukh  |\n",
      "|worldnews      |2026-01-23 00:06:24|As Trump, in Davos, hails Gaza prosperity, Palestinians dig for trash to burn to keep warm                                                                                                              |3    |Delicious_Adeptness9|\n",
      "|technology     |2026-01-23 00:04:16|Palantir helps Ukraine train interceptor drone brains                                                                                                                                                   |1    |Logical_Welder3467  |\n",
      "|technology     |2026-01-22 23:57:52|Ancient telnet bug happily hands out root to attackers                                                                                                                                                  |1    |Logical_Welder3467  |\n",
      "|technology     |2026-01-22 23:55:44|Are AI agents ready for the workplace? A new benchmark raises doubts                                                                                                                                    |1    |Logical_Welder3467  |\n",
      "|technology     |2026-01-22 23:55:44|Microsoft working to fix Outlook email issues                                                                                                                                                           |1    |Logical_Welder3467  |\n",
      "|ProgrammerHumor|2026-01-22 23:47:12|theLinkDoesntWork                                                                                                                                                                                       |1    |DanTheMan827        |\n",
      "|worldnews      |2026-01-22 23:40:48|White House and China finalize deal to sell control of U.S. TikTok business to investors backed by Trump administration                                                                                 |2    |WriterDave          |\n",
      "|news           |2026-01-22 23:28:00|Chinese whistleblower detained by ICE imprisoned in Broome County Jail                                                                                                                                  |3    |Ok-Lets-Talk-It-Out |\n",
      "|technology     |2026-01-22 23:25:52|Nvidia is reportedly cutting RTX 50-series production to focus on AI demand                                                                                                                             |1    |PaiDuck             |\n",
      "|worldnews      |2026-01-22 23:21:36|LGBTQ+ people are important to global economy, corporate allies say at Davos                                                                                                                            |1    |Fickle-Ad5449       |\n",
      "|ProgrammerHumor|2026-01-22 23:08:48|theDevilMadeMeDoIt                                                                                                                                                                                      |0    |soap94              |\n",
      "|news           |2026-01-22 23:00:16|The US wants to remake Venezuelas oil industry. History stands in the way                                                                                                                              |2    |hyeran_jainros_fc   |\n",
      "|technology     |2026-01-22 22:45:20|KSU students express privacy concerns over AI surveillance devices on campus                                                                                                                            |1    |Haunterblademoi     |\n",
      "|technology     |2026-01-22 22:45:20|KSU students express privacy concerns over AI surveillance devices on campus                                                                                                                            |13   |Haunterblademoi     |\n",
      "|worldnews      |2026-01-22 22:41:04|Trump sparks anger with claim Nato troops avoided Afghanistan front line                                                                                                                                |4    |Friendly-Frieren    |\n",
      "|technology     |2026-01-22 22:34:40|Apple to Revamp Siri as a Built-In iPhone, Mac Chatbot to Fend Off OpenAI                                                                                                                               |1    |lurker_bee          |\n",
      "|news           |2026-01-22 22:32:32|Verdict reached in trial for man accused in murder plot against Bovino                                                                                                                                  |2    |edfitz83            |\n",
      "|news           |2026-01-22 22:32:32|Verdict reached in trial for man accused in murder plot against Bovino                                                                                                                                  |92   |edfitz83            |\n",
      "|worldnews      |2026-01-22 22:28:16|Ukraine's Zelenskyy says his repeated warnings to Europe feel like 'Groundhog Day'                                                                                                                      |3    |ConsistentFangirl   |\n",
      "|technology     |2026-01-22 22:28:16|Japan restarts world's largest nuclear plant as Fukushima memories loom large                                                                                                                           |1    |lurker_bee          |\n",
      "|worldnews      |2026-01-22 22:26:08|CBS News contributor among 3 journalists killed by Israel in Gaza                                                                                                                                       |1    |lurker_bee          |\n",
      "|worldnews      |2026-01-22 22:04:48|Train collides with crane in Spains fourth rail crash in a week, several injured                                                                                                                       |3    |Saffron_Cloud       |\n",
      "|technology     |2026-01-22 22:02:40|White House Posts AI-Altered Photo of Arrested Protester                                                                                                                                                |4    |Well_Socialized     |\n",
      "|technology     |2026-01-22 21:54:08|Intel struggles to meet AI demand                                                                                                                                                                       |2    |Franco1875          |\n",
      "|worldnews      |2026-01-22 21:52:00|South Korea launches development of electronic warfare aircraft for deployment in 2034                                                                                                                  |1    |self-fix            |\n",
      "|ProgrammerHumor|2026-01-22 21:52:00|broCanYouHelpMeWithMyCode                                                                                                                                                                               |1    |SNJVGFN902348       |\n",
      "|ProgrammerHumor|2026-01-22 21:52:00|broCanYouHelpMeWithMyCode                                                                                                                                                                               |1    |SNJVGFN902348       |\n",
      "|technology     |2026-01-22 21:47:44|White House posts digitally altered image of woman arrested after ICE protest                                                                                                                           |3    |esporx              |\n",
      "|worldnews      |2026-01-22 21:43:28|Iran seizes assets to punish dissent                                                                                                                                                                    |1    |Christian-Rep-Perisa|\n",
      "|news           |2026-01-22 21:43:28|Zes gewonden bij steekpartij in omgeving Operaplein Antwerpen, 2 slachtoffers in levensgevaar | VRT NWS: nieuws                                                                                         |0    |Ava166              |\n",
      "|news           |2026-01-22 21:41:20|Former Iowa superintendent pleads guilty to falsely claiming US citizenship                                                                                                                             |1    |katrinakt8          |\n",
      "|ProgrammerHumor|2026-01-22 21:39:12|neverAskForHelpDebugging                                                                                                                                                                                |3    |HademLeFashie       |\n",
      "|technology     |2026-01-22 21:39:12|Meijer introduces new bottle return machine that can sort in seconds | \"You don't have to sort anything, it's not one at a time, you just throw them in the bin, close the door and let it do its thing\"|2    |TylerFortier_Photo  |\n",
      "|ProgrammerHumor|2026-01-22 21:34:56|typeScript                                                                                                                                                                                              |2    |hdgamer1404Jonas    |\n",
      "|worldnews      |2026-01-22 21:32:48|U.S. mulls full military withdrawal from Syria.                                                                                                                                                         |1    |Larrydog            |\n",
      "|technology     |2026-01-22 21:32:48|Samsung refutes claims of '80% price hike' across all memory products  leaks and rumors denied by Samsung PR amidst historic RAM shortages                                                             |0    |snowfordessert      |\n",
      "|worldnews      |2026-01-22 21:28:32|Big North European investors reassess US exposure as geopolitical risk mounts                                                                                                                           |1    |goldstarflag        |\n",
      "|news           |2026-01-22 21:26:24|White House posts digitally altered image of woman arrested after ICE protest                                                                                                                           |1    |JackThaBongRipper   |\n",
      "|worldnews      |2026-01-22 21:13:36|'It's all about the land': Zelensky says Ukraine to talk to US and Russia                                                                                                                               |1    |Friendly-Frieren    |\n",
      "|technology     |2026-01-22 21:13:36|South Korea enacts world's first comprehensive AI safety law                                                                                                                                            |1    |self-fix            |\n",
      "|worldnews      |2026-01-22 21:09:20|US abandons Kurdish allies as Syrias new government seizes control                                                                                                                                     |4    |Mitchs_bitch1942    |\n",
      "|news           |2026-01-22 21:07:12|US abandons Kurdish allies as Syrias new government seizes control                                                                                                                                     |1    |Mitchs_bitch1942    |\n",
      "|ProgrammerHumor|2026-01-22 21:07:12|vibeCodersAreJustLearningToCode                                                                                                                                                                         |1    |abhbhbls            |\n",
      "|news           |2026-01-22 21:02:56|Immigration officials allow suspect in $100M jewelry heist to self deport, avoiding trial                                                                                                               |1    |errantv             |\n",
      "|ProgrammerHumor|2026-01-22 21:02:56|askedChatgptToMakeAMemeThatOnlyCopilotAiWouldUnderstand                                                                                                                                                 |1    |lethaldose318       |\n",
      "|worldnews      |2026-01-22 20:58:40|US carrier group deploys to Middle East | The Jerusalem Post                                                                                                                                            |1    |phoeebsy            |\n",
      "|worldnews      |2026-01-22 20:48:00|South Korea becomes first in the world to pass law on safe use of AI                                                                                                                                    |5    |self-fix            |\n",
      "|worldnews      |2026-01-22 20:45:52|Iran warns 'finger on trigger' as Trump says Tehran wants talks                                                                                                                                         |1    |slakmehl            |\n",
      "|technology     |2026-01-22 20:39:28|Older and Large Firms Produce More Patents but Startups Inventions Are More Impactful                                                                                                                  |1    |ClownFetish1776     |\n",
      "|technology     |2026-01-22 20:37:20|A Tesla Actually Drove Itself from Los Angeles to New York: Exclusive                                                                                                                                   |1    |DonkeyFuel          |\n",
      "|ProgrammerHumor|2026-01-22 20:35:12|noCommentNeeded                                                                                                                                                                                         |1    |PERSONAULTRAVESANIAM|\n",
      "|technology     |2026-01-22 20:33:04|Introducing the Niantic Spatial University Partner Program | Niantic Spatial, Inc.                                                                                                                      |1    |ExtensionEcho3      |\n",
      "|news           |2026-01-22 20:24:32|China Could Have 1,000 J-20 Mighty Dragon Fighters in Just 4 Years                                                                                                                                      |3    |Street_Exercise_4844|\n",
      "|news           |2026-01-22 20:18:08|Helping pets left behind after their owners were detained by ICE                                                                                                                                        |25   |Moon_Rose_Violet    |\n",
      "|news           |2026-01-22 20:18:08|Helping pets left behind after their owners were detained by ICE                                                                                                                                        |1    |Moon_Rose_Violet    |\n",
      "|news           |2026-01-22 20:13:52|Ghislaine Maxwell to testify before US Congress in Epstein probe                                                                                                                                        |1    |Flickypicker        |\n",
      "+---------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Union all dataframes and sort\n",
    "if dfs:\n",
    "    # Union all dataframes found\n",
    "    # takes 10 min\n",
    "    full_df = reduce(DataFrame.unionAll, dfs)\n",
    "    \n",
    "    # Sort by created_utc (most recent first)\n",
    "    # created_utc is likely a float timestamp\n",
    "    sorted_df = full_df.orderBy(col(\"created_utc\").desc())\n",
    "    \n",
    "    # Show result (selecting a few relevant columns)\n",
    "    # takes 10 min\n",
    "    display_df = sorted_df.withColumn(\"created_time\", from_unixtime(\"created_utc\")) \\\n",
    "                          .select(\"subreddit\", \"created_time\", \"title\", \"score\", \"author\")\n",
    "    \n",
    "    print(f\"Total records: {sorted_df.count()}\")\n",
    "    display_df.show(100, truncate=False)\n",
    "else:\n",
    "    print(\"No data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a364e870",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
